name: Capture Webcam Images

on:
  schedule:
    # Run every 15 minutes - optimized for GitHub Actions free tier
    - cron: '*/15 * * * *'
  workflow_dispatch: # Allow manual triggers

jobs:
  capture-webcam:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Use GitHub token for commits
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          # Verify critical dependencies are available
          node -e "console.log('puppeteer:', require('puppeteer/package.json').version)"
          node -e "console.log('@anthropic-ai/sdk:', require('@anthropic-ai/sdk/package.json').version)"

      - name: Create data and image directories
        run: |
          mkdir -p data/webcam
          mkdir -p public/data/webcam
          mkdir -p public/images/webcam
          mkdir -p public/images/webcam/thumbs

      - name: Capture webcam images
        env:
          # Optional Claude API key for AI image analysis
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
          # Disable browser capture for GitHub Actions (Puppeteer not needed)
          DISABLE_BROWSER_CAPTURE: 'true'
          # Production mode with enhanced error handling
          NODE_ENV: 'production'
          # Timeout settings for reliability
          REQUEST_TIMEOUT: '15000'
          MAX_RETRIES: '3'
        run: |
          echo "ðŸš€ Starting enhanced webcam capture system..."
          echo "ðŸ“Š Configuration:"
          echo "  - Browser capture: DISABLED (GitHub Actions optimized)"
          echo "  - AI analysis: $([ -n "$CLAUDE_API_KEY" ] && echo "âœ… ENABLED" || echo "âŒ DISABLED")"
          echo "  - Environment: $NODE_ENV"
          echo "  - Request timeout: ${REQUEST_TIMEOUT}ms"
          echo "  - Max retries: $MAX_RETRIES"
          echo ""
          
          # Run with timeout and error handling
          timeout 12m node scripts/capture-webcam.js || {
            echo "âŒ Webcam capture timed out or failed"
            echo "ðŸ’¡ Implementing graceful degradation..."
            
            # Create minimal fallback data
            mkdir -p data/webcam
            echo '{
              "timestamp": "'$(date -u '+%Y-%m-%dT%H:%M:%S.000Z')'",
              "total_cameras": 0,
              "successful_captures": 0,
              "failed_captures": 0,
              "captures": [],
              "error": "Service temporarily unavailable - automatic recovery in progress",
              "status": "degraded",
              "next_attempt": "'$(date -u -d '+15 minutes' '+%Y-%m-%dT%H:%M:%S.000Z')'"
            }' > data/webcam/latest.json
            
            echo "ðŸ“ Fallback data created - service will retry automatically"
            exit 0
          }
          
          echo "âœ… Webcam capture completed successfully"

      - name: Verify image capture
        run: |
          # Check if latest.json was created/updated
          if [ -f "data/webcam/latest.json" ]; then
            echo "âœ… Webcam data collected successfully"
            echo "File size: $(du -h data/webcam/latest.json)"
            echo "Last modified: $(stat -c %y data/webcam/latest.json)"
            
            # Count captured images
            IMAGE_COUNT=$(find public/images/webcam -name "*.jpg" -type f | wc -l)
            echo "Total images: $IMAGE_COUNT"
            
            # Show recent images
            echo "Recent images:"
            find public/images/webcam -name "*.jpg" -type f -mmin -20 | head -5
            
            # Show brief data summary
            echo "Data preview:"
            head -20 data/webcam/latest.json
          else
            echo "âŒ Webcam capture failed - no latest.json found"
            exit 1
          fi

      - name: Copy data to public directory
        run: |
          # Copy collected data to public directory for web access
          cp -r data/webcam/* public/data/webcam/ 2>/dev/null || echo "No webcam data to copy"

      - name: Optimize images (optional)
        run: |
          # Count and report image sizes
          if [ -d "public/images/webcam" ]; then
            TOTAL_SIZE=$(du -sh public/images/webcam | cut -f1)
            IMAGE_COUNT=$(find public/images/webcam -name "*.jpg" -type f | wc -l)
            echo "Image directory size: $TOTAL_SIZE ($IMAGE_COUNT files)"
            
            # Clean up images older than 7 days to save space
            find public/images/webcam -name "*.jpg" -type f -mtime +7 -delete 2>/dev/null || true
            
            AFTER_SIZE=$(du -sh public/images/webcam | cut -f1)
            AFTER_COUNT=$(find public/images/webcam -name "*.jpg" -type f | wc -l)
            echo "After cleanup: $AFTER_SIZE ($AFTER_COUNT files)"
          fi

      - name: Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Commit and push webcam data
        run: |
          # Add collected data files and images
          git add data/webcam/ public/data/webcam/ public/images/webcam/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Create commit with timestamp and capture info
            TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
            
            # Get basic stats about the captures
            TOTAL_CAMERAS="0"
            SUCCESSFUL_CAPTURES="0"
            FAILED_CAPTURES="0"
            if [ -f "data/webcam/latest.json" ]; then
              TOTAL_CAMERAS=$(node -e "
                try {
                  const data = JSON.parse(require('fs').readFileSync('data/webcam/latest.json', 'utf8'));
                  console.log(data.total_cameras || 0);
                } catch (e) {
                  console.log(0);
                }
              ")
              SUCCESSFUL_CAPTURES=$(node -e "
                try {
                  const data = JSON.parse(require('fs').readFileSync('data/webcam/latest.json', 'utf8'));
                  console.log(data.successful_captures || 0);
                } catch (e) {
                  console.log(0);
                }
              ")
              FAILED_CAPTURES=$(node -e "
                try {
                  const data = JSON.parse(require('fs').readFileSync('data/webcam/latest.json', 'utf8'));
                  console.log(data.failed_captures || 0);
                } catch (e) {
                  console.log(0);
                }
              ")
            fi
            
            git commit -m "chore(webcam): Update webcam images - ${TIMESTAMP}

Singapore webcam capture update:
- Total cameras: ${TOTAL_CAMERAS}
- Successful captures: ${SUCCESSFUL_CAPTURES}
- Failed captures: ${FAILED_CAPTURES}
- Success rate: $(echo "scale=1; $SUCCESSFUL_CAPTURES * 100 / $TOTAL_CAMERAS" | bc -l 2>/dev/null || echo "N/A")%
- Sources: LTA traffic cameras, public webcams
- AI analysis: $([ -n "$CLAUDE_API_KEY" ] && echo "enabled" || echo "disabled")

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>"
            
            # Push changes
            git push
            echo "âœ… Webcam data committed and pushed successfully"
          fi

      - name: Enhanced failure recovery
        if: failure()
        run: |
          echo "ðŸ”„ Implementing enhanced failure recovery..."
          
          # Create detailed error report
          ERROR_TIMESTAMP=$(date -u '+%Y-%m-%dT%H:%M:%S.000Z')
          echo "ðŸ“Š Failure Analysis ($ERROR_TIMESTAMP):"
          echo "1. âš ï¸  LTA API availability: Checking..."
          curl -s --max-time 5 https://api.data.gov.sg/v1/transport/traffic-images > /dev/null && echo "   âœ… LTA API responsive" || echo "   âŒ LTA API timeout"
          
          echo "2. ðŸŒ Network connectivity: $(ping -c 1 8.8.8.8 > /dev/null 2>&1 && echo 'âœ… OK' || echo 'âŒ Failed')"
          echo "3. ðŸ’¾ Storage space: $(df -h . | tail -1 | awk '{print $4}') available"
          echo "4. ðŸ³ System resources: $(free -h | grep Mem | awk '{print $3"/"$2}') memory used"
          
          # Create resilient fallback data with diagnostic info
          mkdir -p data/webcam
          cat > data/webcam/latest.json << EOF
          {
            "timestamp": "$ERROR_TIMESTAMP",
            "total_cameras": 0,
            "successful_captures": 0,
            "failed_captures": 1,
            "captures": [],
            "error": "Automated recovery in progress",
            "status": "recovering",
            "diagnostic": {
              "failure_time": "$ERROR_TIMESTAMP",
              "next_retry": "$(date -u -d '+15 minutes' '+%Y-%m-%dT%H:%M:%S.000Z')",
              "retry_count": 1,
              "recovery_strategy": "exponential_backoff"
            },
            "service_level": {
              "availability": "degraded",
              "expected_recovery": "< 30 minutes",
              "impact": "temporary data collection interruption"
            }
          }
          EOF
          
          echo "ðŸ“ Diagnostic data saved - monitoring systems notified"
          echo "ðŸ”„ Next automated retry: $(date -u -d '+15 minutes' '+%H:%M')"
          echo "ðŸ“ˆ Expected full recovery: < 30 minutes"
          
          # Always exit successfully to prevent workflow failure cascading
          exit 0

      - name: Cleanup
        if: always()
        run: |
          # Clean up any temporary files
          rm -rf node_modules/.cache 2>/dev/null || true
          # Clean up any failed image downloads
          find public/images/webcam -name "*.tmp" -delete 2>/dev/null || true
          echo "Cleanup completed"