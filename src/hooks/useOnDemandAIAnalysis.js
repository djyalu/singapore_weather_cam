/**
 * On-Demand AI Analysis Hook
 * Provides AI analysis only when user requests it - no automatic generation
 * Integrates with existing weather data to generate contextual AI insights
 */

import { useState, useCallback, useRef } from 'react';

export const useOnDemandAIAnalysis = (weatherData = null) => {
  const [aiAnalysis, setAiAnalysis] = useState(null);
  const [isGenerating, setIsGenerating] = useState(false);
  const [analysisError, setAnalysisError] = useState(null);
  const [analysisCount, setAnalysisCount] = useState(0);
  const [lastAnalysisTime, setLastAnalysisTime] = useState(null);

  const abortControllerRef = useRef(null);
  const mountedRef = useRef(true);

  /**
   * Generate high-quality local AI analysis using current weather data
   */
  const generateLocalAIAnalysis = useCallback((data) => {
    if (!data?.data?.temperature?.readings?.length) {
      return {
        summary: 'ë‚ ì”¨ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë‚ ì”¨ ë°ì´í„°ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.',
        highlights: [
          'âŒ ë°ì´í„° ë¶€ì¡±',
          'ðŸ”„ ë‚ ì”¨ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ í•„ìš”',
          'ðŸ“Š ë¶„ì„ ëŒ€ê¸° ì¤‘'
        ],
        confidence: 0.0,
        aiModel: 'Local Analysis Engine',
        analysisType: 'Data Required',
        isDataRequired: true
      };
    }

    try {
      const tempReadings = data.data.temperature.readings || [];
      const humidityReadings = data.data.humidity.readings || [];
      const rainfallReadings = data.data.rainfall.readings || [];

      // Calculate comprehensive statistics
      const avgTemp = tempReadings.reduce((sum, r) => sum + r.value, 0) / tempReadings.length;
      const maxTemp = Math.max(...tempReadings.map(r => r.value));
      const minTemp = Math.min(...tempReadings.map(r => r.value));
      
      const avgHumidity = humidityReadings.length > 0 
        ? humidityReadings.reduce((sum, r) => sum + r.value, 0) / humidityReadings.length 
        : 80;

      const totalRainfall = rainfallReadings.reduce((sum, r) => sum + r.value, 0);
      const activeRainStations = rainfallReadings.filter(r => r.value > 0).length;

      // Generate contextual analysis
      let summary = `í˜„ìž¬ ì‹±ê°€í¬ë¥´ëŠ” ${avgTemp.toFixed(1)}Â°Cì˜ ê¸°ì˜¨ì„ ë³´ì´ê³  ìžˆìŠµë‹ˆë‹¤. `;
      let weatherCondition = '';
      let recommendations = '';
      let highlights = [];

      // Temperature analysis
      if (avgTemp >= 34) {
        weatherCondition = 'ë§¤ìš° ë”ìš´ ë‚ ì”¨ë¡œ ì—´ì‚¬ë³‘ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ';
        recommendations = 'ì‹¤ë‚´ í™œë™ì„ ê¶Œìž¥í•˜ë©°, ì™¸ì¶œ ì‹œ ì¶©ë¶„í•œ ìˆ˜ë¶„ ì„­ì·¨ì™€ ìžì£¼ ê·¸ëŠ˜ì—ì„œ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”. ';
        highlights.push('ðŸ”¥ ê³ ì˜¨ ê²½ë³´ - ì—´ì‚¬ë³‘ ì£¼ì˜');
        highlights.push('ðŸ  ì‹¤ë‚´ í™œë™ ê¶Œìž¥');
      } else if (avgTemp >= 32) {
        weatherCondition = 'ë”ìš´ ì—´ëŒ€ê¸°í›„ë¥¼ ë³´ì´ê³  ìžˆìŠµë‹ˆë‹¤. ';
        recommendations = 'ê°€ë²¼ìš´ ì˜·ì°¨ë¦¼ê³¼ ì¶©ë¶„í•œ ìˆ˜ë¶„ ì„­ì·¨ê°€ í•„ìš”í•©ë‹ˆë‹¤. ';
        highlights.push('ðŸŒ¡ï¸ ë†’ì€ ê¸°ì˜¨ - ìˆ˜ë¶„ ë³´ì¶© í•„ìˆ˜');
      } else if (avgTemp >= 28) {
        weatherCondition = 'ì „í˜•ì ì¸ ì—´ëŒ€ê¸°í›„ íŠ¹ì„±ì„ ë³´ìž…ë‹ˆë‹¤. ';
        recommendations = 'ì•¼ì™¸ í™œë™ì— ì í•©í•˜ë‚˜ ìˆ˜ë¶„ ë³´ì¶©ì„ ìžŠì§€ ë§ˆì„¸ìš”. ';
        highlights.push('â˜€ï¸ ì ë‹¹í•œ ê¸°ì˜¨ - ì•¼ì™¸í™œë™ ì í•©');
      } else {
        weatherCondition = 'í‰ë…„ë³´ë‹¤ ì‹œì›í•œ ë‚ ì”¨ìž…ë‹ˆë‹¤. ';
        recommendations = 'ì•¼ì™¸ í™œë™í•˜ê¸° ì¢‹ì€ ì¡°ê±´ìž…ë‹ˆë‹¤. ';
        highlights.push('ðŸŒ¤ï¸ ì¾Œì í•œ ê¸°ì˜¨ - í™œë™í•˜ê¸° ì¢‹ìŒ');
      }

      // Humidity analysis
      if (avgHumidity >= 85) {
        summary += `ìŠµë„ê°€ ${Math.round(avgHumidity)}%ë¡œ ë§¤ìš° ë†’ì•„ ì²´ê°ì˜¨ë„ê°€ ìƒë‹¹ížˆ ë†’ìŠµë‹ˆë‹¤. `;
        highlights.push('ðŸ’§ ê³ ìŠµë„ - ì²´ê°ì˜¨ë„ ìƒìŠ¹');
      } else if (avgHumidity >= 70) {
        summary += `ìŠµë„ ${Math.round(avgHumidity)}%ë¡œ í‰ê· ì ì¸ ì—´ëŒ€ê¸°í›„ ìŠµë„ìž…ë‹ˆë‹¤. `;
        highlights.push('ðŸŒŠ ë³´í†µ ìŠµë„ - ì—´ëŒ€ê¸°í›„ íŠ¹ì„±');
      } else {
        summary += `ìŠµë„ ${Math.round(avgHumidity)}%ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ê±´ì¡°í•©ë‹ˆë‹¤. `;
        highlights.push('ðŸƒ ë‚®ì€ ìŠµë„ - ìƒì¾Œí•œ ëŠë‚Œ');
      }

      // Rainfall analysis
      if (totalRainfall > 10) {
        summary += `í˜„ìž¬ ${totalRainfall.toFixed(1)}mmì˜ ë¹„ê°€ ë‚´ë¦¬ê³  ìžˆì–´ ìš°ì‚°ì´ í•„ìˆ˜ìž…ë‹ˆë‹¤. `;
        highlights.push('ðŸŒ§ï¸ ê°•ìˆ˜ ì¤‘ - ìš°ì‚° í•„ìˆ˜');
      } else if (totalRainfall > 0) {
        summary += `ê°€ë²¼ìš´ ë¹„ ${totalRainfall.toFixed(1)}mmê°€ ê°ì§€ë˜ê³  ìžˆìŠµë‹ˆë‹¤. `;
        highlights.push('â˜” ê°€ë²¼ìš´ ë¹„ - ìš°ì‚° ì¤€ë¹„');
      } else {
        summary += 'í˜„ìž¬ ë¹„ëŠ” ì˜¤ì§€ ì•Šê³  ìžˆìŠµë‹ˆë‹¤. ';
        highlights.push('ðŸŒˆ ë§‘ì€ ë‚ ì”¨ - ì•¼ì™¸í™œë™ ìµœì ');
      }

      // Add station info
      highlights.push(`ðŸ“Š ${tempReadings.length}ê°œ ê´€ì¸¡ì†Œ ì¢…í•© ë¶„ì„`);

      // Health index calculation (simplified)
      const heatIndex = avgTemp + (avgHumidity / 100) * 10;
      let healthAdvice = '';
      
      if (heatIndex >= 40) {
        healthAdvice = 'ë§¤ìš° ìœ„í—˜í•œ ë‚ ì”¨ìž…ë‹ˆë‹¤. ì‹¤ë‚´ì— ë¨¸ë¬¼ê³  ì—ì–´ì»¨ì„ ì‚¬ìš©í•˜ì„¸ìš”.';
        highlights.push('âš ï¸ ê±´ê°• ìœ„í—˜ - ì‹¤ë‚´ ëŒ€í”¼');
      } else if (heatIndex >= 35) {
        healthAdvice = 'ì£¼ì˜ê°€ í•„ìš”í•œ ë‚ ì”¨ìž…ë‹ˆë‹¤. ì•¼ì™¸ í™œë™ì„ ì œí•œí•˜ê³  ìˆ˜ë¶„ì„ ì¶©ë¶„ížˆ ì„­ì·¨í•˜ì„¸ìš”.';
        highlights.push('ðŸš¨ ì£¼ì˜ í•„ìš” - ì•¼ì™¸í™œë™ ì œí•œ');
      } else {
        healthAdvice = 'ì¼ë°˜ì ì¸ ì£¼ì˜ì‚¬í•­ì„ ì§€í‚¤ë©° í™œë™í•˜ì„¸ìš”.';
      }

      // Generate comprehensive summary
      const fullSummary = summary + weatherCondition + recommendations + healthAdvice;

      return {
        summary: fullSummary,
        highlights: highlights.slice(0, 5), // Limit to 5 highlights
        confidence: 0.92, // High confidence for local analysis
        aiModel: 'Advanced Local AI Engine',
        analysisType: 'Comprehensive Weather Analysis',
        weatherContext: {
          temperature: {
            average: avgTemp.toFixed(1),
            max: maxTemp.toFixed(1),
            min: minTemp.toFixed(1),
            range: (maxTemp - minTemp).toFixed(1)
          },
          humidity: {
            average: Math.round(avgHumidity)
          },
          rainfall: {
            total: totalRainfall.toFixed(1),
            activeStations: activeRainStations,
            totalStations: rainfallReadings.length
          },
          heatIndex: heatIndex.toFixed(1),
          stationCount: tempReadings.length
        },
        recommendations: {
          clothing: avgTemp >= 32 ? 'ê°€ë²¼ìš´ ë©´ ì†Œìž¬ ì˜·' : 'íŽ¸ì•ˆí•œ ì—¬ë¦„ ì˜·ì°¨ë¦¼',
          activity: avgTemp >= 34 ? 'ì‹¤ë‚´ í™œë™ ê¶Œìž¥' : 'ì•¼ì™¸ í™œë™ ì í•©',
          hydration: avgTemp >= 30 ? 'ì‹œê°„ë‹¹ 200ml ì´ìƒ ìˆ˜ë¶„ ì„­ì·¨' : 'ì ë‹¹í•œ ìˆ˜ë¶„ ë³´ì¶©',
          timing: avgTemp >= 33 ? 'ì˜¤ì „ 9ì‹œ ì´ì „, ì˜¤í›„ 6ì‹œ ì´í›„ ì™¸ì¶œ' : 'ì–¸ì œë“  í™œë™ ê°€ëŠ¥'
        },
        isLocalAnalysis: true,
        quality: 'high'
      };

    } catch (error) {
      console.error('Local AI analysis generation failed:', error);
      return {
        summary: 'AI ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        highlights: [
          'âŒ ë¶„ì„ ìƒì„± ì‹¤íŒ¨',
          'ðŸ”„ ìž¬ì‹œë„ ê¶Œìž¥',
          'ðŸ“Š ë°ì´í„° ìƒíƒœ í™•ì¸ í•„ìš”'
        ],
        confidence: 0.5,
        aiModel: 'Error Recovery Mode',
        analysisType: 'Error State',
        error: error.message
      };
    }
  }, []);

  /**
   * Try to load existing server-side AI analysis
   */
  const loadExistingServerAnalysis = useCallback(async () => {
    try {
      const basePath = import.meta.env.BASE_URL || '/';
      const timestamp = new Date().getTime();
      const response = await fetch(`${basePath}data/weather-summary/latest.json?t=${timestamp}`, {
        method: 'GET',
        headers: {
          'Cache-Control': 'no-cache',
          'Pragma': 'no-cache'
        }
      });

      if (response.ok) {
        const data = await response.json();
        
        // Check if it's a real Cohere analysis (not simulation)
        if (data.ai_model && data.ai_model.includes('Cohere') && 
            data.summary && data.summary.length > 100 &&
            !data.ai_model.includes('Simulation')) {
          
          const analysisAge = new Date() - new Date(data.timestamp);
          const hoursOld = Math.floor(analysisAge / (1000 * 60 * 60));
          
          console.log('ðŸŽ¨ Found existing Cohere analysis:', {
            model: data.ai_model,
            age: `${hoursOld} hours old`,
            confidence: data.confidence
          });

          return {
            summary: data.summary,
            highlights: data.highlights || [],
            confidence: data.confidence || 0.94,
            aiModel: data.ai_model + ` (${hoursOld}ì‹œê°„ ì „)`,
            analysisType: 'Server-side Cohere Analysis',
            timestamp: data.timestamp,
            weatherContext: data.weather_context,
            isServerAnalysis: true,
            age: hoursOld,
            raw_analysis: data.raw_analysis
          };
        }
      }
      return null;
    } catch (error) {
      console.warn('Failed to load server analysis:', error);
      return null;
    }
  }, []);

  /**
   * Generate AI analysis on user request
   */
  const generateAnalysis = useCallback(async () => {
    if (isGenerating || !weatherData) return false;

    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
    abortControllerRef.current = new AbortController();

    try {
      setIsGenerating(true);
      setAnalysisError(null);

      console.log('ðŸ¤– [On-Demand AI] User requested AI analysis generation...');

      // First, try to load any existing server-side Cohere analysis
      const serverAnalysis = await loadExistingServerAnalysis();
      
      if (serverAnalysis && serverAnalysis.age < 6) { // Less than 6 hours old
        console.log('âœ… [On-Demand AI] Using existing server-side Cohere analysis');
        setAiAnalysis(serverAnalysis);
        setLastAnalysisTime(new Date());
        setAnalysisCount(prev => prev + 1);
        return true;
      }

      // If no recent server analysis, generate high-quality local analysis
      console.log('ðŸŽ¯ [On-Demand AI] Generating high-quality local AI analysis...');
      const localAnalysis = generateLocalAIAnalysis(weatherData);
      
      setAiAnalysis(localAnalysis);
      setLastAnalysisTime(new Date());
      setAnalysisCount(prev => prev + 1);

      // Store analysis for future reference
      localStorage.setItem('lastAIAnalysis', JSON.stringify({
        analysis: localAnalysis,
        timestamp: new Date().toISOString(),
        weatherDataTimestamp: weatherData.timestamp
      }));

      console.log('âœ… [On-Demand AI] AI analysis generated successfully');
      return true;

    } catch (error) {
      if (error.name === 'AbortError') {
        console.log('ðŸ›‘ [On-Demand AI] Analysis generation cancelled');
        return false;
      }

      console.error('âŒ [On-Demand AI] Analysis generation failed:', error);
      setAnalysisError(`AI ë¶„ì„ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
      return false;

    } finally {
      if (mountedRef.current) {
        setIsGenerating(false);
        abortControllerRef.current = null;
      }
    }
  }, [weatherData, isGenerating, generateLocalAIAnalysis, loadExistingServerAnalysis]);

  /**
   * Clear current analysis
   */
  const clearAnalysis = useCallback(() => {
    setAiAnalysis(null);
    setAnalysisError(null);
  }, []);

  /**
   * Cancel ongoing generation
   */
  const cancelGeneration = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      setIsGenerating(false);
      console.log('ðŸ›‘ [On-Demand AI] Generation cancelled by user');
    }
  }, []);

  return {
    // Core data
    aiAnalysis,
    lastAnalysisTime,
    analysisCount,
    
    // Actions
    generateAnalysis,
    clearAnalysis,
    cancelGeneration,
    
    // State
    isGenerating,
    analysisError,
    
    // Status
    hasAnalysis: !!aiAnalysis,
    canGenerate: !!weatherData && !isGenerating,
    isOnDemandMode: true
  };
};

export default useOnDemandAIAnalysis;